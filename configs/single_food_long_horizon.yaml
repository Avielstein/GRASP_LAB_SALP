# Single Food Long Horizon Navigation
# Train agent for sustained, careful navigation over longer time periods

environment:
  name: salp_single_food_long_horizon
  type: salp_snake
  width: 800
  height: 600
  params:
    num_food_items: 1
    food_reward: 1000.0
    collision_penalty: -500.0  # Higher penalty to really discourage wall hits
    time_penalty: -0.5  # Lower time penalty for longer episodes
    proximity_reward_weight: 3.0  # Encourage moving toward food
    respawn_food: true  # Continuous task
    forced_breathing: true
    max_steps_without_food: 2000  # Allow time to navigate carefully
    efficiency_bonus: 0.0

agent:
  name: sac_long_horizon
  type: sac
  hidden_sizes: [256, 256]
  learning_rate: 0.0003
  batch_size: 256  # Larger batch for more stable learning
  buffer_size: 100000  # Larger buffer for long episodes
  gamma: 0.995  # Higher gamma for long-term rewards
  tau: 0.005
  params:
    alpha: 0.2  # Lower alpha = more exploitation
    target_entropy: -0.5
    alpha_lr: 0.0003

training:
  max_episodes: 1000
  max_steps_per_episode: 8000  # Long episodes!
  eval_frequency: 50
  save_frequency: 100
  start_training_after: 1000  # Collect more experience first
  train_frequency: 1
  log_dir: data/logs
  model_dir: data/models
  experiment_name: single_food_long_horizon

gail:
  use_gail: false
